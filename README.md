# PyTorch-Adversarial-Examples
Adversarial attacks against CIFAR-10 and MNIST. These examples use IBM's [Adversarial Robustness Toolbox (ART)](https://adversarial-robustness-toolbox.readthedocs.io/en/latest/guide/setup.html) to generate adversarial examples to attack PyTorch models. Might include more methods against more data sets in the future.
