# PyTorch-Adversarial-Examples
Adversarial attacks against CIFAR-10 and MNIST. The notebooks use [IBM's Adversarial Robustness Toolbox (ART)](https://adversarial-robustness-toolbox.readthedocs.io/en/latest/index.html) to generate adversarial examples to attack PyTorch models. Might include more methods against more datasets in the future.
